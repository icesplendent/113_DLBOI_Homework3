{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dBIMBMpa8LZ"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XdshpulRajCG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optims\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.functional import InterpolationMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nwp7lRWlbX_s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 0 GPUs\n",
            "CUDA is available: False\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "gpu_count = torch.cuda.device_count()\n",
        "\n",
        "print(\"Using\", gpu_count, \"GPUs\")\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O-QHGGMMbBur"
      },
      "outputs": [],
      "source": [
        "# train loop\n",
        "def train_one_epoch(model, device, criterion, optimizer, train_data_loader):\n",
        "    epoch_loss = []\n",
        "    epoch_acc = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate (train_data_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(images)\n",
        "        loss = criterion(preds, labels.unsqueeze(1))\n",
        "\n",
        "        # Calculating Loss\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        # Calculating Metrics\n",
        "        predicts = (preds > 0.5).float()\n",
        "        predicts = predicts.view(-1)\n",
        "        predicts = predicts.detach().cpu().numpy()\n",
        "        labels = labels.detach().cpu().numpy()\n",
        "        acc = accuracy_score(labels, predicts)\n",
        "\n",
        "        epoch_acc.append(acc)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Overall Epoch Results\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "    epoch_acc = np.mean(epoch_acc) * 100\n",
        "\n",
        "    return epoch_loss, epoch_acc, total_time\n",
        "\n",
        "# validation loop\n",
        "def val_one_epoch(model, device, criterion, val_data_loader, best_acc, save):\n",
        "    epoch_loss = []\n",
        "    epoch_acc = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device).float()\n",
        "            preds = model(images)\n",
        "\n",
        "            # Calculating Loss\n",
        "            loss = criterion(preds, labels.unsqueeze(1))\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "            # Calculating Metrics\n",
        "            predicts = (preds > 0.5).float()\n",
        "            predicts = predicts.view(-1)\n",
        "            predicts = predicts.detach().cpu().numpy()\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "            acc = accuracy_score(labels, predicts)\n",
        "            epoch_acc.append(acc)\n",
        "\n",
        "    # Overall Epoch Results\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "    epoch_acc = np.mean(epoch_acc) * 100\n",
        "\n",
        "    # Saving best model\n",
        "    if epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        torch.save(model.state_dict(), f\"{save}.pth\")\n",
        "\n",
        "    return epoch_loss, epoch_acc, total_time, best_acc\n",
        "\n",
        "# evaluate loop (test loop)\n",
        "def evaluate(model, device, model_path, test_loader):\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        print(\"Model weights loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Warning: Failed to load model weights. Using randomly initialized weights instead.\")\n",
        "        print(e)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device).float()\n",
        "\n",
        "            # Forward pass\n",
        "            preds = model(images)\n",
        "\n",
        "            # Calculating loss\n",
        "            loss = criterion(preds, labels.unsqueeze(1))\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            # Calculating accuracy\n",
        "            predicts = (preds > 0.5).float()\n",
        "            predicts = predicts.view(-1)\n",
        "            predicts = predicts.detach().cpu().numpy()\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "            acc = accuracy_score(labels, predicts)\n",
        "            test_acc.append(acc)\n",
        "\n",
        "    # Overall test results\n",
        "    avg_test_loss = np.mean(test_loss)\n",
        "    avg_test_acc = np.mean(test_acc) * 100\n",
        "\n",
        "    print(f\"Test Accuracy: {avg_test_acc:.2f}%\")\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "    return avg_test_loss, avg_test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Mz1-uybSmC"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWULx9svbXJD",
        "outputId": "a3eca7ae-5d93-45b2-faa9-c88685c50a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DpL62qzsbkcj"
      },
      "outputs": [],
      "source": [
        "# define folder path for each set\n",
        "# train_path = '/content/drive/MyDrive/PhD/DLBOI/Lab 3/chest_xray/train'\n",
        "# test_path = '/content/drive/MyDrive/PhD/DLBOI/Lab 3/chest_xray/test'\n",
        "# val_path = '/content/drive/MyDrive/PhD/DLBOI/Lab 3/chest_xray/val'\n",
        "train_path = '/Users/icesplendent/Desktop/DL_biotech/Hw/Hw3/chest_xray/train'\n",
        "test_path = '/Users/icesplendent/Desktop/DL_biotech/Hw/Hw3/chest_xray/test'\n",
        "val_path = '/Users/icesplendent/Desktop/DL_biotech/Hw/Hw3/chest_xray/val'\n",
        "\n",
        "# define transformation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256), interpolation=InterpolationMode.BICUBIC),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "common_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256), interpolation=InterpolationMode.BICUBIC),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# create datasets\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(test_path, transform=common_transform)\n",
        "val_dataset = datasets.ImageFolder(val_path, transform=common_transform)\n",
        "\n",
        "# create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxPrGZFPmvoO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ml-6AVUimusM"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      2\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[1;32m      3\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     nn\u001b[38;5;241m.\u001b[39mSigmoid()\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
            "File \u001b[0;32m~/Desktop/DL_biotech/Hw/Hw3/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/DL_biotech/Hw/Hw3/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/DL_biotech/Hw/Hw3/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/DL_biotech/Hw/Hw3/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/Desktop/DL_biotech/Hw/Hw3/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256 * 256 * 1, 64),\n",
        "    nn.BatchNorm1d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "\n",
        "    nn.Linear(64, 64),\n",
        "    nn.BatchNorm1d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "\n",
        "    nn.Linear(64, 64),\n",
        "    nn.BatchNorm1d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "\n",
        "    nn.Linear(64, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdTAY4X1CXUu"
      },
      "source": [
        "# Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_EzCFAjCWp9"
      },
      "outputs": [],
      "source": [
        "# hyperparameter\n",
        "lr = 0.001\n",
        "weight_decay = 0.001\n",
        "lr_scheduler = optims.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='max')\n",
        "epochs = 10\n",
        "optimizer = optims.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# save checkpoint\n",
        "save = 'model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxdqJu8wCae3"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "best_acc = 0.0\n",
        "output_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc, train_time = train_one_epoch(model, device, criterion, optimizer, train_loader)\n",
        "    val_loss, val_acc, val_time, best_acc = val_one_epoch(model, device, criterion, val_loader, best_acc, save)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    total_time = train_time + val_time\n",
        "    output_str = f\"Epoch {epoch+1}/{epochs} - loss: {train_loss:.4f} - train_acc: {train_acc:.2f}% - val_loss: {val_loss:.4f} - val_acc: {val_acc:.2f}% - time: {total_time:.2f}s\"\n",
        "    output_list.append(output_str)\n",
        "    print(output_str)\n",
        "    lr_scheduler.step(val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGz-VUPmCgf4"
      },
      "source": [
        "# Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an1QmoF0CjAV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# loss graph\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# accuracy graph\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "# show\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5W5mX4KH0eg"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50oemy4aH2nW"
      },
      "outputs": [],
      "source": [
        "model_path = 'model.pth'\n",
        "avg_test_loss, avg_test_acc = evaluate(model, device, model_path, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
